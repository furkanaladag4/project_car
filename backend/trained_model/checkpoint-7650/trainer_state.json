{
  "best_global_step": 7400,
  "best_metric": 4.14672327041626,
  "best_model_checkpoint": "./trained_model/checkpoint-7400",
  "epoch": 10.0,
  "eval_steps": 200,
  "global_step": 7650,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032679738562091505,
      "grad_norm": 0.6799058318138123,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 5.6284,
      "step": 25
    },
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 0.5494704842567444,
      "learning_rate": 2.45e-06,
      "loss": 5.6109,
      "step": 50
    },
    {
      "epoch": 0.09803921568627451,
      "grad_norm": 0.5979481935501099,
      "learning_rate": 3.7e-06,
      "loss": 5.5275,
      "step": 75
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.6760693192481995,
      "learning_rate": 4.95e-06,
      "loss": 5.5936,
      "step": 100
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.5480814576148987,
      "learning_rate": 6.2e-06,
      "loss": 5.4818,
      "step": 125
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.518254816532135,
      "learning_rate": 7.45e-06,
      "loss": 5.3854,
      "step": 150
    },
    {
      "epoch": 0.22875816993464052,
      "grad_norm": 0.5797075033187866,
      "learning_rate": 8.7e-06,
      "loss": 5.2912,
      "step": 175
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.5432839393615723,
      "learning_rate": 9.95e-06,
      "loss": 5.1573,
      "step": 200
    },
    {
      "epoch": 0.26143790849673204,
      "eval_loss": 5.208827972412109,
      "eval_runtime": 139.5921,
      "eval_samples_per_second": 87.641,
      "eval_steps_per_second": 2.744,
      "step": 200
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.5618305802345276,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 5.124,
      "step": 225
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.5226547718048096,
      "learning_rate": 1.245e-05,
      "loss": 5.0285,
      "step": 250
    },
    {
      "epoch": 0.35947712418300654,
      "grad_norm": 0.5122280120849609,
      "learning_rate": 1.3700000000000001e-05,
      "loss": 4.9348,
      "step": 275
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 0.3915032148361206,
      "learning_rate": 1.4950000000000001e-05,
      "loss": 4.8321,
      "step": 300
    },
    {
      "epoch": 0.42483660130718953,
      "grad_norm": 0.3851930499076843,
      "learning_rate": 1.4999605383709391e-05,
      "loss": 4.6938,
      "step": 325
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.33677494525909424,
      "learning_rate": 1.4998355126061342e-05,
      "loss": 4.6189,
      "step": 350
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.2865976095199585,
      "learning_rate": 1.4996248684710133e-05,
      "loss": 4.5588,
      "step": 375
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.2833106815814972,
      "learning_rate": 1.4993286300175286e-05,
      "loss": 4.5238,
      "step": 400
    },
    {
      "epoch": 0.5228758169934641,
      "eval_loss": 4.554949760437012,
      "eval_runtime": 139.6183,
      "eval_samples_per_second": 87.625,
      "eval_steps_per_second": 2.743,
      "step": 400
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.3014402985572815,
      "learning_rate": 1.4989468310710359e-05,
      "loss": 4.4907,
      "step": 425
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.29311099648475647,
      "learning_rate": 1.4984795152264352e-05,
      "loss": 4.5232,
      "step": 450
    },
    {
      "epoch": 0.6209150326797386,
      "grad_norm": 0.23535653948783875,
      "learning_rate": 1.4979267358431902e-05,
      "loss": 4.4455,
      "step": 475
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.26700130105018616,
      "learning_rate": 1.497288556039237e-05,
      "loss": 4.4957,
      "step": 500
    },
    {
      "epoch": 0.6862745098039216,
      "grad_norm": 0.2774866223335266,
      "learning_rate": 1.4965650486837765e-05,
      "loss": 4.4306,
      "step": 525
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.24598367512226105,
      "learning_rate": 1.4957562963889547e-05,
      "loss": 4.3849,
      "step": 550
    },
    {
      "epoch": 0.7516339869281046,
      "grad_norm": 0.261355996131897,
      "learning_rate": 1.4948623915004294e-05,
      "loss": 4.3859,
      "step": 575
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.3010200560092926,
      "learning_rate": 1.493883436086825e-05,
      "loss": 4.4209,
      "step": 600
    },
    {
      "epoch": 0.7843137254901961,
      "eval_loss": 4.402705192565918,
      "eval_runtime": 139.8076,
      "eval_samples_per_second": 87.506,
      "eval_steps_per_second": 2.739,
      "step": 600
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.2636205852031708,
      "learning_rate": 1.49281954192808e-05,
      "loss": 4.38,
      "step": 625
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.26818230748176575,
      "learning_rate": 1.4916708305026821e-05,
      "loss": 4.3764,
      "step": 650
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.2476065754890442,
      "learning_rate": 1.4904374329737974e-05,
      "loss": 4.2906,
      "step": 675
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 0.33133310079574585,
      "learning_rate": 1.489119490174295e-05,
      "loss": 4.3835,
      "step": 700
    },
    {
      "epoch": 0.9477124183006536,
      "grad_norm": 0.3153357207775116,
      "learning_rate": 1.4877171525906654e-05,
      "loss": 4.3626,
      "step": 725
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.2089998424053192,
      "learning_rate": 1.4862305803458373e-05,
      "loss": 4.3479,
      "step": 750
    },
    {
      "epoch": 1.0130718954248366,
      "grad_norm": 0.2538699805736542,
      "learning_rate": 1.4846599431808953e-05,
      "loss": 4.3345,
      "step": 775
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 0.26877450942993164,
      "learning_rate": 1.4830054204356973e-05,
      "loss": 4.4092,
      "step": 800
    },
    {
      "epoch": 1.0457516339869282,
      "eval_loss": 4.347600936889648,
      "eval_runtime": 139.961,
      "eval_samples_per_second": 87.41,
      "eval_steps_per_second": 2.736,
      "step": 800
    },
    {
      "epoch": 1.0784313725490196,
      "grad_norm": 0.3488568067550659,
      "learning_rate": 1.4812672010283976e-05,
      "loss": 4.3009,
      "step": 825
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.2507302463054657,
      "learning_rate": 1.4794454834338757e-05,
      "loss": 4.3518,
      "step": 850
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.23698008060455322,
      "learning_rate": 1.4775404756610735e-05,
      "loss": 4.2736,
      "step": 875
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.2457900047302246,
      "learning_rate": 1.4755523952292443e-05,
      "loss": 4.3503,
      "step": 900
    },
    {
      "epoch": 1.2091503267973855,
      "grad_norm": 0.316848486661911,
      "learning_rate": 1.4734814691431167e-05,
      "loss": 4.3693,
      "step": 925
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.24128182232379913,
      "learning_rate": 1.4713279338669727e-05,
      "loss": 4.339,
      "step": 950
    },
    {
      "epoch": 1.2745098039215685,
      "grad_norm": 0.23275819420814514,
      "learning_rate": 1.4690920352976495e-05,
      "loss": 4.2782,
      "step": 975
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.26673179864883423,
      "learning_rate": 1.4667740287364609e-05,
      "loss": 4.3703,
      "step": 1000
    },
    {
      "epoch": 1.3071895424836601,
      "eval_loss": 4.330798625946045,
      "eval_runtime": 139.702,
      "eval_samples_per_second": 87.572,
      "eval_steps_per_second": 2.742,
      "step": 1000
    },
    {
      "epoch": 1.3398692810457518,
      "grad_norm": 0.5110527873039246,
      "learning_rate": 1.4643741788600475e-05,
      "loss": 4.3374,
      "step": 1025
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.28168174624443054,
      "learning_rate": 1.4619935790635377e-05,
      "loss": 4.2633,
      "step": 1050
    },
    {
      "epoch": 1.4052287581699345,
      "grad_norm": 0.6044611930847168,
      "learning_rate": 1.4594341198174643e-05,
      "loss": 4.2892,
      "step": 1075
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.3094203472137451,
      "learning_rate": 1.4567936553480262e-05,
      "loss": 4.2466,
      "step": 1100
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.44720593094825745,
      "learning_rate": 1.4540724871510331e-05,
      "loss": 4.3186,
      "step": 1125
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 0.7491375803947449,
      "learning_rate": 1.4512709259372775e-05,
      "loss": 4.3155,
      "step": 1150
    },
    {
      "epoch": 1.5359477124183005,
      "grad_norm": 5.545923709869385,
      "learning_rate": 1.448389291597057e-05,
      "loss": 4.3083,
      "step": 1175
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 5.020959377288818,
      "learning_rate": 1.4454279131636492e-05,
      "loss": 4.2583,
      "step": 1200
    },
    {
      "epoch": 1.5686274509803921,
      "eval_loss": 4.318774223327637,
      "eval_runtime": 139.7029,
      "eval_samples_per_second": 87.572,
      "eval_steps_per_second": 2.742,
      "step": 1200
    },
    {
      "epoch": 1.6013071895424837,
      "grad_norm": 1.114014983177185,
      "learning_rate": 1.4423871287757402e-05,
      "loss": 4.3172,
      "step": 1225
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 9.155200958251953,
      "learning_rate": 1.4392672856388167e-05,
      "loss": 4.3331,
      "step": 1250
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 15.486315727233887,
      "learning_rate": 1.4360687399855195e-05,
      "loss": 4.2318,
      "step": 1275
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 28.15970802307129,
      "learning_rate": 1.4327918570349687e-05,
      "loss": 4.2222,
      "step": 1300
    },
    {
      "epoch": 1.7320261437908497,
      "grad_norm": 20.960851669311523,
      "learning_rate": 1.4294370109510621e-05,
      "loss": 4.3137,
      "step": 1325
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 21.150487899780273,
      "learning_rate": 1.4260045847997513e-05,
      "loss": 4.1933,
      "step": 1350
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 17.9880313873291,
      "learning_rate": 1.4224949705053035e-05,
      "loss": 4.2716,
      "step": 1375
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 4.603705883026123,
      "learning_rate": 1.4189085688055481e-05,
      "loss": 4.2859,
      "step": 1400
    },
    {
      "epoch": 1.8300653594771243,
      "eval_loss": 4.2661452293396,
      "eval_runtime": 140.044,
      "eval_samples_per_second": 87.358,
      "eval_steps_per_second": 2.735,
      "step": 1400
    },
    {
      "epoch": 1.8627450980392157,
      "grad_norm": 0.36461469531059265,
      "learning_rate": 1.415245789206122e-05,
      "loss": 4.2833,
      "step": 1425
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 22.1618709564209,
      "learning_rate": 1.4115070499337092e-05,
      "loss": 4.2245,
      "step": 1450
    },
    {
      "epoch": 1.9281045751633987,
      "grad_norm": 2.891227960586548,
      "learning_rate": 1.4076927778882875e-05,
      "loss": 4.2151,
      "step": 1475
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 1.4826536178588867,
      "learning_rate": 1.403803408594383e-05,
      "loss": 4.228,
      "step": 1500
    },
    {
      "epoch": 1.9934640522875817,
      "grad_norm": 4.115702152252197,
      "learning_rate": 1.3998393861513415e-05,
      "loss": 4.2172,
      "step": 1525
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 5.263404846191406,
      "learning_rate": 1.3958011631826195e-05,
      "loss": 4.2232,
      "step": 1550
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 15.426509857177734,
      "learning_rate": 1.3916892007841023e-05,
      "loss": 4.1907,
      "step": 1575
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 1.463065266609192,
      "learning_rate": 1.3875039684714548e-05,
      "loss": 4.2064,
      "step": 1600
    },
    {
      "epoch": 2.0915032679738563,
      "eval_loss": 4.244631290435791,
      "eval_runtime": 139.7397,
      "eval_samples_per_second": 87.548,
      "eval_steps_per_second": 2.741,
      "step": 1600
    },
    {
      "epoch": 2.1241830065359477,
      "grad_norm": 0.3355821371078491,
      "learning_rate": 1.3832459441265114e-05,
      "loss": 4.1828,
      "step": 1625
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 4.132185459136963,
      "learning_rate": 1.3789156139427088e-05,
      "loss": 4.1522,
      "step": 1650
    },
    {
      "epoch": 2.189542483660131,
      "grad_norm": 0.38637861609458923,
      "learning_rate": 1.3745134723695727e-05,
      "loss": 4.2717,
      "step": 1675
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.46323248744010925,
      "learning_rate": 1.3700400220562584e-05,
      "loss": 4.2126,
      "step": 1700
    },
    {
      "epoch": 2.2549019607843137,
      "grad_norm": 1.2877663373947144,
      "learning_rate": 1.365495773794159e-05,
      "loss": 4.2134,
      "step": 1725
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 0.5103635787963867,
      "learning_rate": 1.360881246458579e-05,
      "loss": 4.2474,
      "step": 1750
    },
    {
      "epoch": 2.3202614379084965,
      "grad_norm": 1.2163760662078857,
      "learning_rate": 1.3561969669494904e-05,
      "loss": 4.228,
      "step": 1775
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 1.204788327217102,
      "learning_rate": 1.3514434701313678e-05,
      "loss": 4.3104,
      "step": 1800
    },
    {
      "epoch": 2.3529411764705883,
      "eval_loss": 4.237193584442139,
      "eval_runtime": 139.6908,
      "eval_samples_per_second": 87.579,
      "eval_steps_per_second": 2.742,
      "step": 1800
    },
    {
      "epoch": 2.3856209150326797,
      "grad_norm": 1.3928806781768799,
      "learning_rate": 1.3466212987721174e-05,
      "loss": 4.2508,
      "step": 1825
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 0.30830851197242737,
      "learning_rate": 1.3417310034811008e-05,
      "loss": 4.2324,
      "step": 1850
    },
    {
      "epoch": 2.450980392156863,
      "grad_norm": 1.2588862180709839,
      "learning_rate": 1.3367731426462658e-05,
      "loss": 4.1884,
      "step": 1875
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.3583180904388428,
      "learning_rate": 1.3317482823703884e-05,
      "loss": 4.1362,
      "step": 1900
    },
    {
      "epoch": 2.5163398692810457,
      "grad_norm": 0.558492124080658,
      "learning_rate": 1.3266569964064323e-05,
      "loss": 4.2575,
      "step": 1925
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.5355833172798157,
      "learning_rate": 1.3214998660920375e-05,
      "loss": 4.247,
      "step": 1950
    },
    {
      "epoch": 2.581699346405229,
      "grad_norm": 0.3398474156856537,
      "learning_rate": 1.3162774802831403e-05,
      "loss": 4.2295,
      "step": 1975
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 1.6303006410598755,
      "learning_rate": 1.3109904352867369e-05,
      "loss": 4.2303,
      "step": 2000
    },
    {
      "epoch": 2.6143790849673203,
      "eval_loss": 4.231197834014893,
      "eval_runtime": 139.6838,
      "eval_samples_per_second": 87.584,
      "eval_steps_per_second": 2.742,
      "step": 2000
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.38704055547714233,
      "learning_rate": 1.3056393347927948e-05,
      "loss": 4.2047,
      "step": 2025
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 2.187877893447876,
      "learning_rate": 1.3002247898053226e-05,
      "loss": 4.2051,
      "step": 2050
    },
    {
      "epoch": 2.712418300653595,
      "grad_norm": 3.274524688720703,
      "learning_rate": 1.2947474185726024e-05,
      "loss": 4.1067,
      "step": 2075
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 0.6206853985786438,
      "learning_rate": 1.2892078465165981e-05,
      "loss": 4.1544,
      "step": 2100
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 2.4845876693725586,
      "learning_rate": 1.2836067061615411e-05,
      "loss": 4.2207,
      "step": 2125
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.671299159526825,
      "learning_rate": 1.2779446370617087e-05,
      "loss": 4.2409,
      "step": 2150
    },
    {
      "epoch": 2.843137254901961,
      "grad_norm": 0.4737820625305176,
      "learning_rate": 1.2722222857283969e-05,
      "loss": 4.2366,
      "step": 2175
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 1.24421226978302,
      "learning_rate": 1.2664403055560994e-05,
      "loss": 4.1941,
      "step": 2200
    },
    {
      "epoch": 2.8758169934640523,
      "eval_loss": 4.222268581390381,
      "eval_runtime": 139.6892,
      "eval_samples_per_second": 87.58,
      "eval_steps_per_second": 2.742,
      "step": 2200
    },
    {
      "epoch": 2.9084967320261437,
      "grad_norm": 0.3587518036365509,
      "learning_rate": 1.260599356747903e-05,
      "loss": 4.1801,
      "step": 2225
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.43443262577056885,
      "learning_rate": 1.2547001062401015e-05,
      "loss": 4.1961,
      "step": 2250
    },
    {
      "epoch": 2.973856209150327,
      "grad_norm": 1.1692122220993042,
      "learning_rate": 1.2487432276260447e-05,
      "loss": 4.183,
      "step": 2275
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 0.8707883358001709,
      "learning_rate": 1.2427294010792246e-05,
      "loss": 4.2228,
      "step": 2300
    },
    {
      "epoch": 3.0392156862745097,
      "grad_norm": 0.68990159034729,
      "learning_rate": 1.2366593132756118e-05,
      "loss": 4.1539,
      "step": 2325
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 0.4202195405960083,
      "learning_rate": 1.2305336573152483e-05,
      "loss": 4.1399,
      "step": 2350
    },
    {
      "epoch": 3.104575163398693,
      "grad_norm": 0.4998666048049927,
      "learning_rate": 1.2243531326431077e-05,
      "loss": 4.1102,
      "step": 2375
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 0.37178200483322144,
      "learning_rate": 1.2181184449692312e-05,
      "loss": 4.1455,
      "step": 2400
    },
    {
      "epoch": 3.1372549019607843,
      "eval_loss": 4.155176639556885,
      "eval_runtime": 139.8665,
      "eval_samples_per_second": 87.469,
      "eval_steps_per_second": 2.738,
      "step": 2400
    },
    {
      "epoch": 3.1699346405228757,
      "grad_norm": 0.450602650642395,
      "learning_rate": 1.2118303061881461e-05,
      "loss": 4.0992,
      "step": 2425
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 0.32257670164108276,
      "learning_rate": 1.2054894342975808e-05,
      "loss": 4.1504,
      "step": 2450
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 0.37480583786964417,
      "learning_rate": 1.1990965533164818e-05,
      "loss": 4.0739,
      "step": 2475
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 0.3302273452281952,
      "learning_rate": 1.1926523932023421e-05,
      "loss": 4.1739,
      "step": 2500
    },
    {
      "epoch": 3.3006535947712417,
      "grad_norm": 0.551174521446228,
      "learning_rate": 1.186157689767854e-05,
      "loss": 4.2026,
      "step": 2525
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.37385088205337524,
      "learning_rate": 1.1796131845968906e-05,
      "loss": 4.1662,
      "step": 2550
    },
    {
      "epoch": 3.366013071895425,
      "grad_norm": 1.158685564994812,
      "learning_rate": 1.1730196249598303e-05,
      "loss": 4.1194,
      "step": 2575
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.9355762004852295,
      "learning_rate": 1.1663777637282313e-05,
      "loss": 4.1284,
      "step": 2600
    },
    {
      "epoch": 3.3986928104575163,
      "eval_loss": 4.151593208312988,
      "eval_runtime": 139.6504,
      "eval_samples_per_second": 87.605,
      "eval_steps_per_second": 2.743,
      "step": 2600
    },
    {
      "epoch": 3.431372549019608,
      "grad_norm": 0.35919034481048584,
      "learning_rate": 1.159688359288866e-05,
      "loss": 4.1653,
      "step": 2625
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 0.8420979380607605,
      "learning_rate": 1.1529521754571274e-05,
      "loss": 4.1001,
      "step": 2650
    },
    {
      "epoch": 3.496732026143791,
      "grad_norm": 0.3736039698123932,
      "learning_rate": 1.1461699813898134e-05,
      "loss": 4.1809,
      "step": 2675
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.48067161440849304,
      "learning_rate": 1.1393425514973025e-05,
      "loss": 4.1243,
      "step": 2700
    },
    {
      "epoch": 3.5620915032679736,
      "grad_norm": 0.35818925499916077,
      "learning_rate": 1.1324706653551296e-05,
      "loss": 4.148,
      "step": 2725
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 0.49070656299591064,
      "learning_rate": 1.1255551076149718e-05,
      "loss": 4.1449,
      "step": 2750
    },
    {
      "epoch": 3.627450980392157,
      "grad_norm": 0.3274371027946472,
      "learning_rate": 1.1185966679150544e-05,
      "loss": 4.1018,
      "step": 2775
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 1.054171085357666,
      "learning_rate": 1.1115961407899886e-05,
      "loss": 4.0948,
      "step": 2800
    },
    {
      "epoch": 3.6601307189542482,
      "eval_loss": 4.150272846221924,
      "eval_runtime": 139.6611,
      "eval_samples_per_second": 87.598,
      "eval_steps_per_second": 2.742,
      "step": 2800
    },
    {
      "epoch": 3.69281045751634,
      "grad_norm": 0.6096816658973694,
      "learning_rate": 1.1045543255800471e-05,
      "loss": 4.1527,
      "step": 2825
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 0.704460084438324,
      "learning_rate": 1.0974720263398964e-05,
      "loss": 4.089,
      "step": 2850
    },
    {
      "epoch": 3.758169934640523,
      "grad_norm": 0.3221117854118347,
      "learning_rate": 1.090350051746784e-05,
      "loss": 4.1292,
      "step": 2875
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 0.4100545048713684,
      "learning_rate": 1.0831892150082046e-05,
      "loss": 4.1449,
      "step": 2900
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 0.39645159244537354,
      "learning_rate": 1.075990333769043e-05,
      "loss": 4.1076,
      "step": 2925
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 0.6935136914253235,
      "learning_rate": 1.0687542300182146e-05,
      "loss": 4.1926,
      "step": 2950
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 0.706785261631012,
      "learning_rate": 1.0614817299948087e-05,
      "loss": 4.1267,
      "step": 2975
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.37142476439476013,
      "learning_rate": 1.0541736640937437e-05,
      "loss": 4.1277,
      "step": 3000
    },
    {
      "epoch": 3.9215686274509802,
      "eval_loss": 4.149763107299805,
      "eval_runtime": 139.7733,
      "eval_samples_per_second": 87.527,
      "eval_steps_per_second": 2.74,
      "step": 3000
    },
    {
      "epoch": 3.954248366013072,
      "grad_norm": 0.5376207828521729,
      "learning_rate": 1.0468308667709541e-05,
      "loss": 4.1018,
      "step": 3025
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.35033535957336426,
      "learning_rate": 1.0394541764481063e-05,
      "loss": 4.1112,
      "step": 3050
    },
    {
      "epoch": 4.019607843137255,
      "grad_norm": 1.0361324548721313,
      "learning_rate": 1.032044435416867e-05,
      "loss": 4.1172,
      "step": 3075
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 0.3506211042404175,
      "learning_rate": 1.0246024897427281e-05,
      "loss": 4.1819,
      "step": 3100
    },
    {
      "epoch": 4.084967320261438,
      "grad_norm": 0.3269476294517517,
      "learning_rate": 1.0171291891683995e-05,
      "loss": 4.131,
      "step": 3125
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.37328729033470154,
      "learning_rate": 1.0096253870167836e-05,
      "loss": 4.055,
      "step": 3150
    },
    {
      "epoch": 4.150326797385621,
      "grad_norm": 0.6377662420272827,
      "learning_rate": 1.002091940093541e-05,
      "loss": 4.1352,
      "step": 3175
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 0.34918370842933655,
      "learning_rate": 9.945297085892564e-06,
      "loss": 4.0946,
      "step": 3200
    },
    {
      "epoch": 4.183006535947713,
      "eval_loss": 4.148998260498047,
      "eval_runtime": 139.7125,
      "eval_samples_per_second": 87.566,
      "eval_steps_per_second": 2.741,
      "step": 3200
    },
    {
      "epoch": 4.215686274509804,
      "grad_norm": 0.4500199258327484,
      "learning_rate": 9.869395559812215e-06,
      "loss": 4.1682,
      "step": 3225
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.3118470311164856,
      "learning_rate": 9.793223489348392e-06,
      "loss": 4.0948,
      "step": 3250
    },
    {
      "epoch": 4.281045751633987,
      "grad_norm": 2.6224193572998047,
      "learning_rate": 9.71678957204666e-06,
      "loss": 4.1572,
      "step": 3275
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.9554222226142883,
      "learning_rate": 9.640102535351006e-06,
      "loss": 4.1879,
      "step": 3300
    },
    {
      "epoch": 4.34640522875817,
      "grad_norm": 0.39657923579216003,
      "learning_rate": 9.563171135607318e-06,
      "loss": 4.0946,
      "step": 3325
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 0.6476256251335144,
      "learning_rate": 9.486004157063555e-06,
      "loss": 4.0559,
      "step": 3350
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 0.38267362117767334,
      "learning_rate": 9.408610410866739e-06,
      "loss": 4.1287,
      "step": 3375
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.7401626706123352,
      "learning_rate": 9.330998734056877e-06,
      "loss": 4.1572,
      "step": 3400
    },
    {
      "epoch": 4.444444444444445,
      "eval_loss": 4.148691654205322,
      "eval_runtime": 139.7252,
      "eval_samples_per_second": 87.558,
      "eval_steps_per_second": 2.741,
      "step": 3400
    },
    {
      "epoch": 4.477124183006536,
      "grad_norm": 0.4702928066253662,
      "learning_rate": 9.253177988557916e-06,
      "loss": 4.1596,
      "step": 3425
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.8280165791511536,
      "learning_rate": 9.175157060165865e-06,
      "loss": 4.1609,
      "step": 3450
    },
    {
      "epoch": 4.542483660130719,
      "grad_norm": 0.49251291155815125,
      "learning_rate": 9.096944857534195e-06,
      "loss": 4.1175,
      "step": 3475
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 0.4564835727214813,
      "learning_rate": 9.018550311156613e-06,
      "loss": 4.0927,
      "step": 3500
    },
    {
      "epoch": 4.607843137254902,
      "grad_norm": 0.34107375144958496,
      "learning_rate": 8.93998237234736e-06,
      "loss": 4.139,
      "step": 3525
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 0.7176163196563721,
      "learning_rate": 8.861250012219122e-06,
      "loss": 4.1354,
      "step": 3550
    },
    {
      "epoch": 4.673202614379085,
      "grad_norm": 0.8038656115531921,
      "learning_rate": 8.782362220658686e-06,
      "loss": 4.083,
      "step": 3575
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.48692819476127625,
      "learning_rate": 8.703328005300441e-06,
      "loss": 4.1686,
      "step": 3600
    },
    {
      "epoch": 4.705882352941177,
      "eval_loss": 4.148418426513672,
      "eval_runtime": 139.9365,
      "eval_samples_per_second": 87.425,
      "eval_steps_per_second": 2.737,
      "step": 3600
    },
    {
      "epoch": 4.738562091503268,
      "grad_norm": 0.6065633893013,
      "learning_rate": 8.624156390497866e-06,
      "loss": 4.1206,
      "step": 3625
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 0.3399513363838196,
      "learning_rate": 8.54485641629311e-06,
      "loss": 4.1404,
      "step": 3650
    },
    {
      "epoch": 4.803921568627451,
      "grad_norm": 0.5668452978134155,
      "learning_rate": 8.465437137384758e-06,
      "loss": 4.1827,
      "step": 3675
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.48089537024497986,
      "learning_rate": 8.385907622093949e-06,
      "loss": 4.0786,
      "step": 3700
    },
    {
      "epoch": 4.8692810457516345,
      "grad_norm": 0.349951833486557,
      "learning_rate": 8.306276951328939e-06,
      "loss": 4.1276,
      "step": 3725
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 0.42432448267936707,
      "learning_rate": 8.226554217548189e-06,
      "loss": 4.0879,
      "step": 3750
    },
    {
      "epoch": 4.934640522875817,
      "grad_norm": 0.5297340154647827,
      "learning_rate": 8.146748523722195e-06,
      "loss": 4.1381,
      "step": 3775
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.964500367641449,
      "learning_rate": 8.066868982294061e-06,
      "loss": 4.2049,
      "step": 3800
    },
    {
      "epoch": 4.967320261437909,
      "eval_loss": 4.14808988571167,
      "eval_runtime": 139.6895,
      "eval_samples_per_second": 87.58,
      "eval_steps_per_second": 2.742,
      "step": 3800
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.4970724880695343,
      "learning_rate": 7.986924714139025e-06,
      "loss": 4.097,
      "step": 3825
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 0.33846259117126465,
      "learning_rate": 7.906924847523004e-06,
      "loss": 4.1461,
      "step": 3850
    },
    {
      "epoch": 5.065359477124183,
      "grad_norm": 0.32869040966033936,
      "learning_rate": 7.826878517060313e-06,
      "loss": 4.1651,
      "step": 3875
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.3986601233482361,
      "learning_rate": 7.74679486267064e-06,
      "loss": 4.1749,
      "step": 3900
    },
    {
      "epoch": 5.130718954248366,
      "grad_norm": 0.5502910017967224,
      "learning_rate": 7.666683028535423e-06,
      "loss": 4.1399,
      "step": 3925
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 0.46684280037879944,
      "learning_rate": 7.58655216205375e-06,
      "loss": 4.1144,
      "step": 3950
    },
    {
      "epoch": 5.196078431372549,
      "grad_norm": 0.3416203260421753,
      "learning_rate": 7.506411412797869e-06,
      "loss": 4.1339,
      "step": 3975
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 0.35580193996429443,
      "learning_rate": 7.426269931468481e-06,
      "loss": 4.1661,
      "step": 4000
    },
    {
      "epoch": 5.228758169934641,
      "eval_loss": 4.1479082107543945,
      "eval_runtime": 139.7287,
      "eval_samples_per_second": 87.555,
      "eval_steps_per_second": 2.741,
      "step": 4000
    },
    {
      "epoch": 5.261437908496732,
      "grad_norm": 0.6354681849479675,
      "learning_rate": 7.346136868849868e-06,
      "loss": 4.1217,
      "step": 4025
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 1.0894179344177246,
      "learning_rate": 7.266021374765046e-06,
      "loss": 4.1211,
      "step": 4050
    },
    {
      "epoch": 5.326797385620915,
      "grad_norm": 0.29909008741378784,
      "learning_rate": 7.1859325970310044e-06,
      "loss": 4.0956,
      "step": 4075
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 0.8068912029266357,
      "learning_rate": 7.105879680414179e-06,
      "loss": 4.1468,
      "step": 4100
    },
    {
      "epoch": 5.392156862745098,
      "grad_norm": 0.34172770380973816,
      "learning_rate": 7.025871765586285e-06,
      "loss": 4.1343,
      "step": 4125
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 0.3467949330806732,
      "learning_rate": 6.945917988080602e-06,
      "loss": 4.0945,
      "step": 4150
    },
    {
      "epoch": 5.457516339869281,
      "grad_norm": 0.327289342880249,
      "learning_rate": 6.8660274772488545e-06,
      "loss": 4.1191,
      "step": 4175
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.37249240279197693,
      "learning_rate": 6.786209355218801e-06,
      "loss": 4.1647,
      "step": 4200
    },
    {
      "epoch": 5.490196078431373,
      "eval_loss": 4.147839546203613,
      "eval_runtime": 139.8737,
      "eval_samples_per_second": 87.465,
      "eval_steps_per_second": 2.738,
      "step": 4200
    },
    {
      "epoch": 5.522875816993464,
      "grad_norm": 0.3228486180305481,
      "learning_rate": 6.706472735852628e-06,
      "loss": 4.1416,
      "step": 4225
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.8691770434379578,
      "learning_rate": 6.626826723706329e-06,
      "loss": 4.1233,
      "step": 4250
    },
    {
      "epoch": 5.588235294117647,
      "grad_norm": 0.3565512001514435,
      "learning_rate": 6.547280412990093e-06,
      "loss": 4.1413,
      "step": 4275
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 0.4130847752094269,
      "learning_rate": 6.467842886529918e-06,
      "loss": 4.1143,
      "step": 4300
    },
    {
      "epoch": 5.65359477124183,
      "grad_norm": 0.35866543650627136,
      "learning_rate": 6.388523214730507e-06,
      "loss": 4.1536,
      "step": 4325
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 1.0534863471984863,
      "learning_rate": 6.309330454539572e-06,
      "loss": 4.115,
      "step": 4350
    },
    {
      "epoch": 5.718954248366013,
      "grad_norm": 0.740582287311554,
      "learning_rate": 6.230273648413701e-06,
      "loss": 4.1017,
      "step": 4375
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 0.5186778903007507,
      "learning_rate": 6.15136182328585e-06,
      "loss": 4.0821,
      "step": 4400
    },
    {
      "epoch": 5.751633986928105,
      "eval_loss": 4.147707462310791,
      "eval_runtime": 139.6886,
      "eval_samples_per_second": 87.581,
      "eval_steps_per_second": 2.742,
      "step": 4400
    },
    {
      "epoch": 5.784313725490196,
      "grad_norm": 1.2087557315826416,
      "learning_rate": 6.072603989534635e-06,
      "loss": 4.1058,
      "step": 4425
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 0.29719099402427673,
      "learning_rate": 5.994009139955491e-06,
      "loss": 4.127,
      "step": 4450
    },
    {
      "epoch": 5.849673202614379,
      "grad_norm": 0.4839138686656952,
      "learning_rate": 5.915586248733853e-06,
      "loss": 4.1546,
      "step": 4475
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.3628454804420471,
      "learning_rate": 5.8373442704204585e-06,
      "loss": 4.1268,
      "step": 4500
    },
    {
      "epoch": 5.915032679738562,
      "grad_norm": 0.3399721682071686,
      "learning_rate": 5.759292138908888e-06,
      "loss": 4.1038,
      "step": 4525
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 0.3237978219985962,
      "learning_rate": 5.681438766415473e-06,
      "loss": 4.131,
      "step": 4550
    },
    {
      "epoch": 5.980392156862745,
      "grad_norm": 0.4482521414756775,
      "learning_rate": 5.603793042461664e-06,
      "loss": 4.0891,
      "step": 4575
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 0.3731379806995392,
      "learning_rate": 5.526363832859014e-06,
      "loss": 4.134,
      "step": 4600
    },
    {
      "epoch": 6.0130718954248366,
      "eval_loss": 4.147620677947998,
      "eval_runtime": 139.7803,
      "eval_samples_per_second": 87.523,
      "eval_steps_per_second": 2.74,
      "step": 4600
    },
    {
      "epoch": 6.045751633986928,
      "grad_norm": 0.4248051345348358,
      "learning_rate": 5.449159978696838e-06,
      "loss": 4.1136,
      "step": 4625
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 1.043003797531128,
      "learning_rate": 5.372190295332725e-06,
      "loss": 4.1606,
      "step": 4650
    },
    {
      "epoch": 6.111111111111111,
      "grad_norm": 0.4768860936164856,
      "learning_rate": 5.295463571385966e-06,
      "loss": 4.1114,
      "step": 4675
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.8749071359634399,
      "learning_rate": 5.218988567734056e-06,
      "loss": 4.1077,
      "step": 4700
    },
    {
      "epoch": 6.176470588235294,
      "grad_norm": 0.4119967520236969,
      "learning_rate": 5.142774016512336e-06,
      "loss": 4.144,
      "step": 4725
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 0.3324647545814514,
      "learning_rate": 5.06682862011695e-06,
      "loss": 4.1255,
      "step": 4750
    },
    {
      "epoch": 6.241830065359477,
      "grad_norm": 0.31929489970207214,
      "learning_rate": 4.991161050211161e-06,
      "loss": 4.1082,
      "step": 4775
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 0.33140066266059875,
      "learning_rate": 4.915779946735216e-06,
      "loss": 4.1695,
      "step": 4800
    },
    {
      "epoch": 6.2745098039215685,
      "eval_loss": 4.147313594818115,
      "eval_runtime": 139.7048,
      "eval_samples_per_second": 87.57,
      "eval_steps_per_second": 2.741,
      "step": 4800
    },
    {
      "epoch": 6.30718954248366,
      "grad_norm": 0.37160131335258484,
      "learning_rate": 4.8406939169197995e-06,
      "loss": 4.1475,
      "step": 4825
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 0.4294658303260803,
      "learning_rate": 4.765911534303235e-06,
      "loss": 4.1293,
      "step": 4850
    },
    {
      "epoch": 6.372549019607844,
      "grad_norm": 0.41806358098983765,
      "learning_rate": 4.6914413377525464e-06,
      "loss": 4.1428,
      "step": 4875
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 0.35121408104896545,
      "learning_rate": 4.617291830488446e-06,
      "loss": 4.1213,
      "step": 4900
    },
    {
      "epoch": 6.437908496732026,
      "grad_norm": 0.354583203792572,
      "learning_rate": 4.5434714791144335e-06,
      "loss": 4.0872,
      "step": 4925
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.4881487488746643,
      "learning_rate": 4.469988712650036e-06,
      "loss": 4.1167,
      "step": 4950
    },
    {
      "epoch": 6.503267973856209,
      "grad_norm": 0.48826417326927185,
      "learning_rate": 4.396851921568373e-06,
      "loss": 4.0406,
      "step": 4975
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 0.7346606850624084,
      "learning_rate": 4.324069456838101e-06,
      "loss": 4.1839,
      "step": 5000
    },
    {
      "epoch": 6.5359477124183005,
      "eval_loss": 4.147275924682617,
      "eval_runtime": 139.9464,
      "eval_samples_per_second": 87.419,
      "eval_steps_per_second": 2.737,
      "step": 5000
    },
    {
      "epoch": 6.568627450980392,
      "grad_norm": 0.6474514007568359,
      "learning_rate": 4.251649628969872e-06,
      "loss": 4.078,
      "step": 5025
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.48580360412597656,
      "learning_rate": 4.17960070706743e-06,
      "loss": 4.1264,
      "step": 5050
    },
    {
      "epoch": 6.633986928104575,
      "grad_norm": 0.35930773615837097,
      "learning_rate": 4.107930917883403e-06,
      "loss": 4.1254,
      "step": 5075
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.9084044098854065,
      "learning_rate": 4.036648444879961e-06,
      "loss": 4.1282,
      "step": 5100
    },
    {
      "epoch": 6.699346405228758,
      "grad_norm": 0.3654724061489105,
      "learning_rate": 3.965761427294399e-06,
      "loss": 4.1096,
      "step": 5125
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 0.43250709772109985,
      "learning_rate": 3.895277959209782e-06,
      "loss": 4.1473,
      "step": 5150
    },
    {
      "epoch": 6.764705882352941,
      "grad_norm": 0.9050704836845398,
      "learning_rate": 3.8252060886307315e-06,
      "loss": 4.1588,
      "step": 5175
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 0.2939094603061676,
      "learning_rate": 3.75555381656449e-06,
      "loss": 4.1959,
      "step": 5200
    },
    {
      "epoch": 6.7973856209150325,
      "eval_loss": 4.147176265716553,
      "eval_runtime": 139.7437,
      "eval_samples_per_second": 87.546,
      "eval_steps_per_second": 2.741,
      "step": 5200
    },
    {
      "epoch": 6.830065359477124,
      "grad_norm": 0.2923297882080078,
      "learning_rate": 3.686329096107326e-06,
      "loss": 4.0893,
      "step": 5225
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.4804346263408661,
      "learning_rate": 3.6175398315364512e-06,
      "loss": 4.0691,
      "step": 5250
    },
    {
      "epoch": 6.895424836601308,
      "grad_norm": 0.6470383405685425,
      "learning_rate": 3.549193877407468e-06,
      "loss": 4.1085,
      "step": 5275
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 0.5573533177375793,
      "learning_rate": 3.4812990376575235e-06,
      "loss": 4.1338,
      "step": 5300
    },
    {
      "epoch": 6.96078431372549,
      "grad_norm": 0.6258805394172668,
      "learning_rate": 3.4138630647142325e-06,
      "loss": 4.1513,
      "step": 5325
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 0.2954172194004059,
      "learning_rate": 3.3468936586104746e-06,
      "loss": 4.1503,
      "step": 5350
    },
    {
      "epoch": 7.026143790849673,
      "grad_norm": 0.4933314919471741,
      "learning_rate": 3.28039846610519e-06,
      "loss": 4.1625,
      "step": 5375
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.38251444697380066,
      "learning_rate": 3.2143850798102555e-06,
      "loss": 4.0843,
      "step": 5400
    },
    {
      "epoch": 7.0588235294117645,
      "eval_loss": 4.1470465660095215,
      "eval_runtime": 139.735,
      "eval_samples_per_second": 87.551,
      "eval_steps_per_second": 2.741,
      "step": 5400
    },
    {
      "epoch": 7.091503267973856,
      "grad_norm": 0.3874835669994354,
      "learning_rate": 3.148861037323528e-06,
      "loss": 4.1669,
      "step": 5425
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 0.43496808409690857,
      "learning_rate": 3.083833820368189e-06,
      "loss": 4.1197,
      "step": 5450
    },
    {
      "epoch": 7.1568627450980395,
      "grad_norm": 0.30846118927001953,
      "learning_rate": 3.0193108539384455e-06,
      "loss": 4.1535,
      "step": 5475
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 0.435427188873291,
      "learning_rate": 2.9552995054517423e-06,
      "loss": 4.1134,
      "step": 5500
    },
    {
      "epoch": 7.222222222222222,
      "grad_norm": 0.3257690370082855,
      "learning_rate": 2.8918070839075157e-06,
      "loss": 4.0754,
      "step": 5525
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.32437390089035034,
      "learning_rate": 2.828840839052634e-06,
      "loss": 4.1179,
      "step": 5550
    },
    {
      "epoch": 7.287581699346405,
      "grad_norm": 0.359275758266449,
      "learning_rate": 2.766407960553606e-06,
      "loss": 4.1004,
      "step": 5575
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 0.40013712644577026,
      "learning_rate": 2.7045155771756303e-06,
      "loss": 4.0864,
      "step": 5600
    },
    {
      "epoch": 7.3202614379084965,
      "eval_loss": 4.146982669830322,
      "eval_runtime": 139.7637,
      "eval_samples_per_second": 87.533,
      "eval_steps_per_second": 2.74,
      "step": 5600
    },
    {
      "epoch": 7.352941176470588,
      "grad_norm": 0.4357549548149109,
      "learning_rate": 2.643170755968631e-06,
      "loss": 4.1319,
      "step": 5625
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 0.5980059504508972,
      "learning_rate": 2.5823805014603077e-06,
      "loss": 4.1509,
      "step": 5650
    },
    {
      "epoch": 7.4183006535947715,
      "grad_norm": 0.333855539560318,
      "learning_rate": 2.522151754856345e-06,
      "loss": 4.1426,
      "step": 5675
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 0.3857765793800354,
      "learning_rate": 2.462491393247846e-06,
      "loss": 4.1383,
      "step": 5700
    },
    {
      "epoch": 7.483660130718954,
      "grad_norm": 0.3249514698982239,
      "learning_rate": 2.4034062288260743e-06,
      "loss": 4.1846,
      "step": 5725
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 0.31713929772377014,
      "learning_rate": 2.3449030081046404e-06,
      "loss": 4.197,
      "step": 5750
    },
    {
      "epoch": 7.549019607843137,
      "grad_norm": 0.4796338975429535,
      "learning_rate": 2.2869884111491475e-06,
      "loss": 4.119,
      "step": 5775
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 0.3522758483886719,
      "learning_rate": 2.2296690508144478e-06,
      "loss": 4.1192,
      "step": 5800
    },
    {
      "epoch": 7.5816993464052285,
      "eval_loss": 4.146890640258789,
      "eval_runtime": 139.664,
      "eval_samples_per_second": 87.596,
      "eval_steps_per_second": 2.742,
      "step": 5800
    },
    {
      "epoch": 7.61437908496732,
      "grad_norm": 0.4672616422176361,
      "learning_rate": 2.172951471989573e-06,
      "loss": 4.079,
      "step": 5825
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.45297813415527344,
      "learning_rate": 2.116842150850407e-06,
      "loss": 4.139,
      "step": 5850
    },
    {
      "epoch": 7.6797385620915035,
      "grad_norm": 0.5866827368736267,
      "learning_rate": 2.061347494120233e-06,
      "loss": 4.0742,
      "step": 5875
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.37137696146965027,
      "learning_rate": 2.0064738383381863e-06,
      "loss": 4.1226,
      "step": 5900
    },
    {
      "epoch": 7.745098039215686,
      "grad_norm": 0.4808131456375122,
      "learning_rate": 1.9522274491357333e-06,
      "loss": 4.1055,
      "step": 5925
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 0.7778851389884949,
      "learning_rate": 1.8986145205212368e-06,
      "loss": 4.1507,
      "step": 5950
    },
    {
      "epoch": 7.810457516339869,
      "grad_norm": 0.5459657311439514,
      "learning_rate": 1.8456411741727194e-06,
      "loss": 4.1402,
      "step": 5975
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 0.4722181260585785,
      "learning_rate": 1.793313458738862e-06,
      "loss": 4.1256,
      "step": 6000
    },
    {
      "epoch": 7.8431372549019605,
      "eval_loss": 4.146917819976807,
      "eval_runtime": 139.6501,
      "eval_samples_per_second": 87.605,
      "eval_steps_per_second": 2.743,
      "step": 6000
    },
    {
      "epoch": 7.875816993464053,
      "grad_norm": 0.39911559224128723,
      "learning_rate": 1.7416373491483553e-06,
      "loss": 4.2047,
      "step": 6025
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 0.3599072992801666,
      "learning_rate": 1.6906187459276678e-06,
      "loss": 4.1491,
      "step": 6050
    },
    {
      "epoch": 7.9411764705882355,
      "grad_norm": 0.9124265909194946,
      "learning_rate": 1.6402634745272982e-06,
      "loss": 4.1384,
      "step": 6075
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 0.3542538583278656,
      "learning_rate": 1.5905772846566208e-06,
      "loss": 4.0734,
      "step": 6100
    },
    {
      "epoch": 8.006535947712418,
      "grad_norm": 0.6409189105033875,
      "learning_rate": 1.541565849627356e-06,
      "loss": 4.1625,
      "step": 6125
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 0.31435203552246094,
      "learning_rate": 1.493234765705785e-06,
      "loss": 4.1096,
      "step": 6150
    },
    {
      "epoch": 8.071895424836601,
      "grad_norm": 0.36752986907958984,
      "learning_rate": 1.445589551473744e-06,
      "loss": 4.1145,
      "step": 6175
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.33280232548713684,
      "learning_rate": 1.3986356471985037e-06,
      "loss": 4.1227,
      "step": 6200
    },
    {
      "epoch": 8.104575163398692,
      "eval_loss": 4.146845817565918,
      "eval_runtime": 139.9614,
      "eval_samples_per_second": 87.41,
      "eval_steps_per_second": 2.736,
      "step": 6200
    },
    {
      "epoch": 8.137254901960784,
      "grad_norm": 0.8573954701423645,
      "learning_rate": 1.3523784142115753e-06,
      "loss": 4.1154,
      "step": 6225
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.3520149290561676,
      "learning_rate": 1.3068231342965464e-06,
      "loss": 4.1373,
      "step": 6250
    },
    {
      "epoch": 8.202614379084967,
      "grad_norm": 0.35214963555336,
      "learning_rate": 1.2619750090859893e-06,
      "loss": 4.1633,
      "step": 6275
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.6440045833587646,
      "learning_rate": 1.217839159467523e-06,
      "loss": 4.0735,
      "step": 6300
    },
    {
      "epoch": 8.267973856209151,
      "grad_norm": 0.4270173907279968,
      "learning_rate": 1.1744206249990953e-06,
      "loss": 4.2373,
      "step": 6325
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 0.5202819108963013,
      "learning_rate": 1.131724363333549e-06,
      "loss": 4.1241,
      "step": 6350
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.5013502836227417,
      "learning_rate": 1.08975524965255e-06,
      "loss": 4.0994,
      "step": 6375
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 1.1226813793182373,
      "learning_rate": 1.0485180761099192e-06,
      "loss": 4.0676,
      "step": 6400
    },
    {
      "epoch": 8.366013071895425,
      "eval_loss": 4.146862030029297,
      "eval_runtime": 139.7044,
      "eval_samples_per_second": 87.571,
      "eval_steps_per_second": 2.742,
      "step": 6400
    },
    {
      "epoch": 8.398692810457517,
      "grad_norm": 0.5113321542739868,
      "learning_rate": 1.0080175512844548e-06,
      "loss": 4.1657,
      "step": 6425
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.49349445104599,
      "learning_rate": 9.682582996422851e-07,
      "loss": 4.2328,
      "step": 6450
    },
    {
      "epoch": 8.4640522875817,
      "grad_norm": 0.6277294158935547,
      "learning_rate": 9.292448610088441e-07,
      "loss": 4.1393,
      "step": 6475
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 0.480575293302536,
      "learning_rate": 8.909816900504969e-07,
      "loss": 4.0909,
      "step": 6500
    },
    {
      "epoch": 8.529411764705882,
      "grad_norm": 0.29599466919898987,
      "learning_rate": 8.534731557658895e-07,
      "loss": 4.1074,
      "step": 6525
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.34528982639312744,
      "learning_rate": 8.16723540987091e-07,
      "loss": 4.1029,
      "step": 6550
    },
    {
      "epoch": 8.594771241830065,
      "grad_norm": 0.7289267778396606,
      "learning_rate": 7.807370418905585e-07,
      "loss": 4.1437,
      "step": 6575
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 0.42033106088638306,
      "learning_rate": 7.455177675180164e-07,
      "loss": 4.1103,
      "step": 6600
    },
    {
      "epoch": 8.627450980392156,
      "eval_loss": 4.1467719078063965,
      "eval_runtime": 139.8995,
      "eval_samples_per_second": 87.449,
      "eval_steps_per_second": 2.738,
      "step": 6600
    },
    {
      "epoch": 8.660130718954248,
      "grad_norm": 0.4601278603076935,
      "learning_rate": 7.110697393072657e-07,
      "loss": 4.062,
      "step": 6625
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 0.37489083409309387,
      "learning_rate": 6.773968906330091e-07,
      "loss": 4.0927,
      "step": 6650
    },
    {
      "epoch": 8.72549019607843,
      "grad_norm": 0.32587215304374695,
      "learning_rate": 6.44503066357725e-07,
      "loss": 4.1813,
      "step": 6675
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 0.31907594203948975,
      "learning_rate": 6.123920223926497e-07,
      "loss": 4.1858,
      "step": 6700
    },
    {
      "epoch": 8.790849673202615,
      "grad_norm": 1.3132842779159546,
      "learning_rate": 5.810674252689191e-07,
      "loss": 4.126,
      "step": 6725
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.330576092004776,
      "learning_rate": 5.50532851718912e-07,
      "loss": 4.0981,
      "step": 6750
    },
    {
      "epoch": 8.856209150326798,
      "grad_norm": 0.4809494912624359,
      "learning_rate": 5.207917882678478e-07,
      "loss": 4.0955,
      "step": 6775
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 0.3805072009563446,
      "learning_rate": 4.918476308356892e-07,
      "loss": 4.1257,
      "step": 6800
    },
    {
      "epoch": 8.88888888888889,
      "eval_loss": 4.1467413902282715,
      "eval_runtime": 139.6835,
      "eval_samples_per_second": 87.584,
      "eval_steps_per_second": 2.742,
      "step": 6800
    },
    {
      "epoch": 8.92156862745098,
      "grad_norm": 0.5426774024963379,
      "learning_rate": 4.637036843493783e-07,
      "loss": 4.1425,
      "step": 6825
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 0.7863411903381348,
      "learning_rate": 4.363631623654768e-07,
      "loss": 4.1564,
      "step": 6850
    },
    {
      "epoch": 8.986928104575163,
      "grad_norm": 0.5862450003623962,
      "learning_rate": 4.098291867032336e-07,
      "loss": 4.0794,
      "step": 6875
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 0.6137548089027405,
      "learning_rate": 3.841047870881234e-07,
      "loss": 4.0794,
      "step": 6900
    },
    {
      "epoch": 9.052287581699346,
      "grad_norm": 0.37758201360702515,
      "learning_rate": 3.5919290080590586e-07,
      "loss": 4.0453,
      "step": 6925
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 0.5940279960632324,
      "learning_rate": 3.350963723672337e-07,
      "loss": 4.116,
      "step": 6950
    },
    {
      "epoch": 9.117647058823529,
      "grad_norm": 0.4975616931915283,
      "learning_rate": 3.1181795318286465e-07,
      "loss": 4.2135,
      "step": 6975
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 0.32675519585609436,
      "learning_rate": 2.893603012494922e-07,
      "loss": 4.1195,
      "step": 7000
    },
    {
      "epoch": 9.15032679738562,
      "eval_loss": 4.1467390060424805,
      "eval_runtime": 139.691,
      "eval_samples_per_second": 87.579,
      "eval_steps_per_second": 2.742,
      "step": 7000
    },
    {
      "epoch": 9.183006535947712,
      "grad_norm": 0.40756532549858093,
      "learning_rate": 2.6772598084625373e-07,
      "loss": 4.1188,
      "step": 7025
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 0.5314525961875916,
      "learning_rate": 2.4691746224192706e-07,
      "loss": 4.1054,
      "step": 7050
    },
    {
      "epoch": 9.248366013071895,
      "grad_norm": 0.3061376214027405,
      "learning_rate": 2.269371214128696e-07,
      "loss": 4.1924,
      "step": 7075
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 0.6914488077163696,
      "learning_rate": 2.0778723977172926e-07,
      "loss": 4.1393,
      "step": 7100
    },
    {
      "epoch": 9.313725490196079,
      "grad_norm": 0.41817596554756165,
      "learning_rate": 1.8947000390693636e-07,
      "loss": 4.1711,
      "step": 7125
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 0.3296333849430084,
      "learning_rate": 1.7198750533303914e-07,
      "loss": 4.1475,
      "step": 7150
    },
    {
      "epoch": 9.379084967320262,
      "grad_norm": 0.32499080896377563,
      "learning_rate": 1.553417402518889e-07,
      "loss": 4.1212,
      "step": 7175
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.3808101415634155,
      "learning_rate": 1.395346093247024e-07,
      "loss": 4.1066,
      "step": 7200
    },
    {
      "epoch": 9.411764705882353,
      "eval_loss": 4.146726608276367,
      "eval_runtime": 139.662,
      "eval_samples_per_second": 87.597,
      "eval_steps_per_second": 2.742,
      "step": 7200
    },
    {
      "epoch": 9.444444444444445,
      "grad_norm": 0.3378949761390686,
      "learning_rate": 1.2456791745504375e-07,
      "loss": 4.0975,
      "step": 7225
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 0.42516693472862244,
      "learning_rate": 1.1044337358273426e-07,
      "loss": 4.1032,
      "step": 7250
    },
    {
      "epoch": 9.509803921568627,
      "grad_norm": 0.3844985365867615,
      "learning_rate": 9.716259048872106e-08,
      "loss": 4.115,
      "step": 7275
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 0.38841086626052856,
      "learning_rate": 8.472708461092438e-08,
      "loss": 4.1176,
      "step": 7300
    },
    {
      "epoch": 9.57516339869281,
      "grad_norm": 0.2990942597389221,
      "learning_rate": 7.313827587108524e-08,
      "loss": 4.1087,
      "step": 7325
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 0.3418825566768646,
      "learning_rate": 6.239748751263763e-08,
      "loss": 4.1033,
      "step": 7350
    },
    {
      "epoch": 9.640522875816993,
      "grad_norm": 0.7813816070556641,
      "learning_rate": 5.250594594961439e-08,
      "loss": 4.1215,
      "step": 7375
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.6992985606193542,
      "learning_rate": 4.3464780626614184e-08,
      "loss": 4.11,
      "step": 7400
    },
    {
      "epoch": 9.673202614379084,
      "eval_loss": 4.14672327041626,
      "eval_runtime": 139.6711,
      "eval_samples_per_second": 87.592,
      "eval_steps_per_second": 2.742,
      "step": 7400
    },
    {
      "epoch": 9.705882352941176,
      "grad_norm": 0.3213212788105011,
      "learning_rate": 3.5275023889832226e-08,
      "loss": 4.1353,
      "step": 7425
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 0.5032716393470764,
      "learning_rate": 2.7937610869194495e-08,
      "loss": 4.1284,
      "step": 7450
    },
    {
      "epoch": 9.77124183006536,
      "grad_norm": 0.3648104667663574,
      "learning_rate": 2.1453379371570714e-08,
      "loss": 4.1344,
      "step": 7475
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.7360690236091614,
      "learning_rate": 1.582306978511916e-08,
      "loss": 4.124,
      "step": 7500
    },
    {
      "epoch": 9.836601307189543,
      "grad_norm": 0.5119887590408325,
      "learning_rate": 1.1047324994744312e-08,
      "loss": 4.1425,
      "step": 7525
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 0.5166159868240356,
      "learning_rate": 7.126690308687234e-09,
      "loss": 4.0994,
      "step": 7550
    },
    {
      "epoch": 9.901960784313726,
      "grad_norm": 0.4087473154067993,
      "learning_rate": 4.061613396267038e-09,
      "loss": 4.1865,
      "step": 7575
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 0.5768096446990967,
      "learning_rate": 1.8524442367592874e-09,
      "loss": 4.1064,
      "step": 7600
    },
    {
      "epoch": 9.934640522875817,
      "eval_loss": 4.146737098693848,
      "eval_runtime": 139.6248,
      "eval_samples_per_second": 87.621,
      "eval_steps_per_second": 2.743,
      "step": 7600
    },
    {
      "epoch": 9.967320261437909,
      "grad_norm": 0.37859636545181274,
      "learning_rate": 4.994350794387814e-10,
      "loss": 4.0957,
      "step": 7625
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.49869784712791443,
      "learning_rate": 2.7404147717735586e-12,
      "loss": 4.1985,
      "step": 7650
    }
  ],
  "logging_steps": 25,
  "max_steps": 7650,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6591822341668864e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
